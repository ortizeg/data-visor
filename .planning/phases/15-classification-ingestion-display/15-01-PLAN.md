---
phase: 15-classification-ingestion-display
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/repositories/duckdb_repo.py
  - app/models/dataset.py
  - app/models/scan.py
  - app/ingestion/base_parser.py
  - app/ingestion/classification_jsonl_parser.py
  - app/services/folder_scanner.py
  - app/services/ingestion.py
  - app/routers/ingestion.py
  - app/routers/datasets.py
  - app/routers/annotations.py
  - app/routers/statistics.py
autonomous: true

must_haves:
  truths:
    - "POST /ingestion/scan on a folder with JSONL + images returns format='classification_jsonl' with correct splits"
    - "POST /ingestion/import with classification_jsonl splits creates dataset with dataset_type='classification' and annotations with sentinel bbox values (0.0)"
    - "GET /datasets/{id} returns dataset_type field"
    - "PATCH /annotations/{id}/category updates category_name for classification label editing"
    - "Classification annotations have bbox_x=0, bbox_y=0, bbox_w=0, bbox_h=0, area=0 as sentinel values"
  artifacts:
    - path: "app/ingestion/classification_jsonl_parser.py"
      provides: "ClassificationJSONLParser extending BaseParser"
      contains: "class ClassificationJSONLParser"
    - path: "app/repositories/duckdb_repo.py"
      provides: "dataset_type column migration"
      contains: "dataset_type"
    - path: "app/services/folder_scanner.py"
      provides: "Classification JSONL layout detection"
      contains: "classification_jsonl"
  key_links:
    - from: "app/services/folder_scanner.py"
      to: "app/models/scan.py"
      via: "ScanResult with format='classification_jsonl'"
      pattern: "classification_jsonl"
    - from: "app/services/ingestion.py"
      to: "app/ingestion/classification_jsonl_parser.py"
      via: "parser dispatch by format string"
      pattern: "ClassificationJSONLParser"
    - from: "app/services/ingestion.py"
      to: "app/repositories/duckdb_repo.py"
      via: "stores dataset_type on dataset record"
      pattern: "dataset_type"
---

<objective>
Add classification dataset ingestion support to the backend: schema migration, JSONL parser, folder scanner detection, parser dispatch, and annotation category update endpoint.

Purpose: Enable the system to auto-detect, parse, and store classification datasets using the existing ingestion pipeline with sentinel bbox values. This is the backend foundation for all classification display work.
Output: ClassificationJSONLParser, extended FolderScanner, updated IngestionService with parser dispatch, dataset_type column, and category update endpoint.
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/15-classification-ingestion-display/15-RESEARCH.md
@app/ingestion/base_parser.py
@app/ingestion/coco_parser.py
@app/services/folder_scanner.py
@app/services/ingestion.py
@app/repositories/duckdb_repo.py
@app/models/dataset.py
@app/models/scan.py
@app/routers/ingestion.py
@app/routers/datasets.py
@app/routers/annotations.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Schema migration, Pydantic models, and ClassificationJSONLParser</name>
  <files>
    app/repositories/duckdb_repo.py
    app/models/dataset.py
    app/models/scan.py
    app/ingestion/base_parser.py
    app/ingestion/classification_jsonl_parser.py
  </files>
  <action>
    **1. Schema migration** (`app/repositories/duckdb_repo.py`):
    Add after existing ALTER TABLE statements in `initialize_schema()`:
    ```python
    self.connection.execute(
        "ALTER TABLE datasets ADD COLUMN IF NOT EXISTS dataset_type VARCHAR DEFAULT 'detection'"
    )
    ```

    **2. Pydantic models**:
    - `app/models/dataset.py`: Add `dataset_type: str = "detection"` field to `DatasetResponse`.
    - `app/models/scan.py`: No change needed -- `ScanResult.format` already accepts any string. The format field will carry `"classification_jsonl"` for classification datasets.

    **3. BaseParser update** (`app/ingestion/base_parser.py`):
    Add `image_dir: str = ""` parameter to `build_image_batches` abstract method signature if not already present (check COCOParser -- it already has it in the concrete method, ensure the ABC matches).

    **4. ClassificationJSONLParser** (`app/ingestion/classification_jsonl_parser.py` -- NEW FILE):
    Create parser extending BaseParser with:

    - `format_name` property returns `"classification_jsonl"`
    - `parse_categories(file_path)`: Single pass over JSONL, collect unique labels from flexible keys (`label`, `class`, `category`, `class_name`). Return `{i: name for i, name in enumerate(sorted(labels))}`.
    - `build_image_batches(file_path, dataset_id, split, image_dir)`: Read JSONL line by line. For each line, extract filename from flexible keys (`filename`, `file_name`, `image`, `path`). Generate sample_id as `f"{split}_{i}"` if split else `str(i)`. Yield DataFrames with columns matching samples table: `id, dataset_id, file_name, width, height, thumbnail_path, split, metadata, image_dir`. Set width=0, height=0 (resolved during thumbnail generation). Use `self.batch_size` for batching.
    - `build_annotation_batches(file_path, dataset_id, categories, split)`: Read JSONL again. For each line, extract label using same flexible keys. Create annotation row with sentinel bbox values: `bbox_x=0.0, bbox_y=0.0, bbox_w=0.0, bbox_h=0.0, area=0.0, is_crowd=False, source="ground_truth", confidence=None, metadata=None`. Sample IDs must match those from `build_image_batches` (same `f"{split}_{i}"` pattern). Annotation IDs: `f"{split}_ann_{i}"` or `f"ann_{i}"`.

    Handle edge cases:
    - Skip empty lines
    - If `label` is an array, emit one annotation row per label (forward-compatible for multi-label)
    - Use `"unknown"` as fallback label if no label key found
  </action>
  <verify>
    - `python -c "from app.ingestion.classification_jsonl_parser import ClassificationJSONLParser; p = ClassificationJSONLParser(); print(p.format_name)"` prints `classification_jsonl`
    - `python -c "from app.models.dataset import DatasetResponse; print(DatasetResponse.model_fields.keys())"` includes `dataset_type`
    - All existing tests pass: `cd app && python -m pytest tests/ -x -q`
  </verify>
  <done>ClassificationJSONLParser exists with parse_categories, build_image_batches, build_annotation_batches producing sentinel bbox annotations. DatasetResponse includes dataset_type. Schema migration adds dataset_type column.</done>
</task>

<task type="auto">
  <name>Task 2: FolderScanner detection, IngestionService dispatch, and API endpoints</name>
  <files>
    app/services/folder_scanner.py
    app/services/ingestion.py
    app/routers/ingestion.py
    app/routers/datasets.py
    app/routers/annotations.py
    app/routers/statistics.py
  </files>
  <action>
    **1. FolderScanner** (`app/services/folder_scanner.py`):
    Extend `scan()` to detect classification JSONL layouts BEFORE trying COCO layouts (classification is more specific -- a JSONL file is never COCO):

    In the local scan path, add before `_try_layout_b`:
    ```python
    splits = self._try_layout_d(Path(resolved), warnings)
    if not splits:
        splits = self._try_layout_e(Path(resolved), warnings)
    if splits:
        return ScanResult(
            root_path=resolved,
            dataset_name=_basename(resolved),
            format="classification_jsonl",
            splits=splits,
            warnings=warnings,
        )
    ```

    Add two new layout detectors:

    `_try_layout_d(root, warnings)` -- **Split directories with JSONL + images**:
    - Use existing `_detect_split_dirs()` to find split dirs
    - In each split dir, look for `.jsonl` files
    - For each `.jsonl` file, call `_is_classification_jsonl(file_path)` (new static method)
    - If valid, count images in the split dir, create DetectedSplit
    - Return list of splits

    `_try_layout_e(root, warnings)` -- **Flat JSONL at root**:
    - Look for `.jsonl` files in root (no recursion)
    - Check if any are classification JSONL via `_is_classification_jsonl()`
    - Image dir: prefer `images/` subdir, else root itself
    - Return single-element split list with name=root.name

    `_is_classification_jsonl(file_path)` -- **Static method**:
    - Open file, read first 5 non-empty lines
    - Parse each as JSON
    - Return True if line has (`filename` or `file_name` or `image` or `path`) AND (`label` or `class` or `category` or `class_name`) AND NOT (`bbox` or `annotations`)
    - Catch all exceptions, return False

    For GCS: Add similar classification detection in `_scan_gcs()` -- check for `.jsonl` files before `.json` files. Use `_is_classification_jsonl_remote()` that reads via `self.storage.open()`.

    **2. IngestionService** (`app/services/ingestion.py`):
    - Add import for ClassificationJSONLParser at top
    - In `ingest_with_progress()`, replace hardcoded `COCOParser(batch_size=1000)` with format-based dispatch:
      ```python
      if format == "coco":
          parser = COCOParser(batch_size=1000)
      elif format == "classification_jsonl":
          parser = ClassificationJSONLParser(batch_size=1000)
      else:
          raise ValueError(f"Unsupported format: {format}")
      ```
    - After the dataset INSERT (step 4), for new datasets set dataset_type:
      ```python
      dataset_type = "classification" if format == "classification_jsonl" else "detection"
      ```
      Include `dataset_type` in the INSERT VALUES. Update the INSERT statement to include the new column. For the UPDATE path (existing dataset), no change needed -- dataset_type is set on first insert.
    - Update the existing INSERT INTO datasets to include `dataset_type` column. The INSERT currently uses positional VALUES -- add `dataset_type` after `prediction_count` (or adjust column list). Be careful to match column order.

    **3. Ingestion router** (`app/routers/ingestion.py`):
    - The `/ingestion/import` endpoint passes `format` through to `ingest_with_progress`. Currently it may not pass format. Ensure the ImportRequest or the stored ScanResult format is threaded through. The simplest approach: add `format: str = "coco"` field to `ImportRequest` model in `app/models/scan.py`, then pass it in the ingestion router's import endpoint to `ingest_with_progress()`.

    **4. Datasets router** (`app/routers/datasets.py`):
    - Ensure the `GET /datasets` and `GET /datasets/{id}` queries include `dataset_type` in SELECT. Currently using `SELECT *` or explicit columns -- add `dataset_type` to the result mapping into `DatasetResponse`.

    **5. Annotations router** (`app/routers/annotations.py`):
    - Add a new endpoint: `PATCH /annotations/{annotation_id}/category` accepting `{"category_name": "new_label"}`. It should UPDATE the annotation's `category_name` in DuckDB. Return 200 with the updated annotation. Use a simple Pydantic model `CategoryUpdateRequest(BaseModel): category_name: str`.

    **6. Statistics router** (`app/routers/statistics.py`):
    - For classification datasets, the `gt_annotations` stat should reflect "labeled images" (count of distinct sample_ids with GT annotations) rather than raw annotation count. Check `dataset_type` from the datasets table, and if `"classification"`, adjust the query. This is a minor conditional in the existing statistics aggregation.
  </action>
  <verify>
    - Create a test JSONL file and verify scanner detection:
      ```bash
      mkdir -p /tmp/test_cls/train && echo '{"filename": "a.jpg", "label": "cat"}' > /tmp/test_cls/train/annotations.jsonl && touch /tmp/test_cls/train/a.jpg
      python -c "
      from app.services.folder_scanner import FolderScanner
      s = FolderScanner()
      r = s.scan('/tmp/test_cls')
      print(f'format={r.format}, splits={len(r.splits)}, split_name={r.splits[0].name if r.splits else None}')
      assert r.format == 'classification_jsonl'
      print('PASS')
      "
      ```
    - All existing tests pass: `cd app && python -m pytest tests/ -x -q`
    - Server starts without errors: `cd app && timeout 5 python -c "from app.main import app; print('OK')" 2>&1 || true`
  </verify>
  <done>FolderScanner detects classification JSONL layouts (D and E). IngestionService dispatches to ClassificationJSONLParser for classification_jsonl format and stores dataset_type. ImportRequest carries format. PATCH /annotations/{id}/category endpoint exists. Statistics endpoint is classification-aware. GET /datasets returns dataset_type. All existing tests pass.</done>
</task>

</tasks>

<verification>
1. Scanner returns format="classification_jsonl" for split-dir JSONL layout
2. Scanner returns format="classification_jsonl" for flat JSONL layout
3. Scanner still returns format="coco" for existing COCO layouts (no regression)
4. Dataset INSERT includes dataset_type="classification" for classification imports
5. DatasetResponse includes dataset_type field
6. PATCH /annotations/{id}/category updates category_name
7. All existing tests pass
</verification>

<success_criteria>
- Classification JSONL folders are auto-detected by the scanner
- Parser produces correct annotations with sentinel bbox values
- dataset_type is stored and returned via API
- Category update endpoint works for classification label editing
- Zero regressions in existing detection workflow
</success_criteria>

<output>
After completion, create `.planning/phases/15-classification-ingestion-display/15-01-SUMMARY.md`
</output>
