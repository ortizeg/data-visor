---
phase: 08-docker-deployment-auth
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Dockerfile.backend
  - app/config.py
  - app/main.py
autonomous: true

must_haves:
  truths:
    - "Backend Docker image builds successfully with all Python dependencies"
    - "CORS middleware is conditionally applied based on behind_proxy setting"
    - "DuckDB WAL is flushed via CHECKPOINT on clean shutdown"
  artifacts:
    - path: "Dockerfile.backend"
      provides: "Multi-stage Python 3.14 + uv backend build"
      contains: "FROM python:3.14-slim"
    - path: "app/config.py"
      provides: "behind_proxy setting for conditional CORS"
      contains: "behind_proxy"
    - path: "app/main.py"
      provides: "Conditional CORS and DuckDB CHECKPOINT on shutdown"
      contains: "CHECKPOINT"
  key_links:
    - from: "Dockerfile.backend"
      to: "pyproject.toml"
      via: "uv sync --frozen copies lockfile deps"
      pattern: "uv sync --frozen"
    - from: "app/main.py"
      to: "app/config.py"
      via: "behind_proxy setting controls CORS"
      pattern: "behind_proxy"
---

<objective>
Create the backend Docker image and fix application config for Docker deployment.

Purpose: The backend Dockerfile is the foundation for the Docker stack. The config fixes (conditional CORS, DuckDB CHECKPOINT) prevent two known pitfalls: CORS spec violation when behind a proxy, and data loss on unclean container shutdown.
Output: Dockerfile.backend (multi-stage build), updated app/config.py and app/main.py
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-docker-deployment-auth/08-RESEARCH.md

@app/main.py
@app/config.py
@pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create multi-stage backend Dockerfile</name>
  <files>Dockerfile.backend</files>
  <action>
Create `Dockerfile.backend` at project root with a two-stage multi-stage build:

**Stage 1 (builder):**
- Base: `python:3.14-slim`
- Copy uv binary from `ghcr.io/astral-sh/uv:latest` to `/usr/local/bin/uv`
- WORKDIR `/app`
- Copy `pyproject.toml` and `uv.lock`
- Run `uv sync --frozen --no-dev --no-editable` to install production deps
- IMPORTANT: For PyTorch CPU-only in Docker, add a separate step BEFORE `uv sync`:
  `RUN uv pip install --python /app/.venv/bin/python torch --index-url https://download.pytorch.org/whl/cpu --no-deps`
  Then run `uv sync --frozen --no-dev --no-editable` which will skip torch (already installed).
  If this approach fails, fall back to: create the venv first with `uv venv`, install torch CPU separately, then `uv sync`.
  The goal is to avoid pulling CUDA wheels (~2.5GB) into the Docker image.

**Stage 2 (runner):**
- Base: `python:3.14-slim`
- Install runtime system deps: `RUN apt-get update && apt-get install -y --no-install-recommends curl && rm -rf /var/lib/apt/lists/*` (curl needed for health check)
- WORKDIR `/app`
- Copy `.venv` from builder stage
- Copy `app/` directory
- Copy `plugins/` directory
- Set `ENV PATH="/app/.venv/bin:$PATH"`
- Set `ENV DATAVISOR_HOST=0.0.0.0`
- Set `ENV DATAVISOR_PORT=8000`
- EXPOSE 8000
- CMD: `["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]`

Do NOT use `python:3.14-alpine` -- numpy/torch have musl compilation issues.
Do NOT include `data/` or `.venv/` in the image -- data is mounted at runtime.
Do NOT add gunicorn -- single-user tool, one uvicorn worker is correct for DuckDB's single-writer constraint.
  </action>
  <verify>Run `docker build -f Dockerfile.backend -t datavisor-backend .` from project root and confirm it completes without errors. Check image size is reasonable (should be under 4GB with CPU torch, ideally ~2GB).</verify>
  <done>Dockerfile.backend exists at project root, builds successfully, and produces an image with all Python dependencies installed using CPU-only PyTorch.</done>
</task>

<task type="auto">
  <name>Task 2: Add behind_proxy setting and fix CORS + DuckDB shutdown</name>
  <files>app/config.py, app/main.py</files>
  <action>
**In `app/config.py`:**
Add a new setting to the Settings class:
```python
behind_proxy: bool = False  # Set DATAVISOR_BEHIND_PROXY=true in Docker
```
This follows the existing `DATAVISOR_` prefix convention, so it is set via `DATAVISOR_BEHIND_PROXY=true`.

**In `app/main.py`:**

1. Make CORS middleware conditional on `behind_proxy` setting. Replace the current unconditional CORS block:
```python
# Current (REMOVE):
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

With conditional CORS applied during lifespan startup (after settings are loaded), or applied at module level with a settings check:
```python
settings = get_settings()
if not settings.behind_proxy:
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:3000"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
```

IMPORTANT: Change `allow_origins` from `["*"]` to `["http://localhost:3000"]`. The wildcard + credentials combination is a CORS spec violation that browsers silently reject. When behind Caddy proxy (same origin), no CORS middleware is needed at all.

2. Add DuckDB CHECKPOINT before close in the lifespan shutdown section. In the shutdown block, add `db.connection.execute("CHECKPOINT")` BEFORE `db.close()`:
```python
# Shutdown
plugin_registry.shutdown()
similarity_service.close()
db.connection.execute("CHECKPOINT")  # Flush WAL to disk before container stops
db.close()
```

This ensures the WAL is flushed to the main database file on clean shutdown, preventing data loss when Docker stops the container.
  </action>
  <verify>Run `cd "/Users/ortizeg/1Projects/⛹️‍♂️ Next Play/code/data-visor" && python -c "from app.config import get_settings; s = get_settings(); print(f'behind_proxy={s.behind_proxy}')"` to confirm the new setting exists and defaults to False. Run `pytest tests/` to confirm existing tests still pass.</verify>
  <done>app/config.py has `behind_proxy: bool = False` setting. app/main.py has conditional CORS (skipped when behind_proxy=True, uses localhost:3000 origin otherwise) and DuckDB CHECKPOINT on shutdown. All existing tests pass.</done>
</task>

</tasks>

<verification>
1. `docker build -f Dockerfile.backend -t datavisor-backend .` completes successfully
2. `python -c "from app.config import get_settings; s = get_settings(); print(s.behind_proxy)"` prints `False`
3. `grep -q "CHECKPOINT" app/main.py` returns 0
4. `grep -q "behind_proxy" app/config.py` returns 0
5. `pytest tests/` passes
</verification>

<success_criteria>
- Backend Docker image builds and contains all Python dependencies with CPU-only PyTorch
- CORS is conditional: off when behind proxy, restricted to localhost:3000 otherwise
- DuckDB CHECKPOINT ensures WAL flush on clean shutdown
- All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/08-docker-deployment-auth/08-01-SUMMARY.md`
</output>
