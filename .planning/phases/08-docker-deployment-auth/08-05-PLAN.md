---
phase: 08-docker-deployment-auth
plan: 05
type: execute
wave: 4
depends_on: ["08-04"]
files_modified:
  - docs/deployment.md
autonomous: false

must_haves:
  truths:
    - "User can follow documentation to run DataVisor locally via Docker"
    - "User can follow documentation to deploy DataVisor to a GCP VM with HTTPS"
    - "User can follow documentation to configure a custom domain"
    - "Full Docker stack starts and serves DataVisor with auth at http://localhost"
  artifacts:
    - path: "docs/deployment.md"
      provides: "Complete deployment guide covering local, GCP, and custom domain setup"
      contains: "docker compose up"
  key_links:
    - from: "docs/deployment.md"
      to: "scripts/run-local.sh"
      via: "references local run script"
      pattern: "run-local"
    - from: "docs/deployment.md"
      to: "scripts/deploy-gcp.sh"
      via: "references GCP deployment script"
      pattern: "deploy-gcp"
    - from: "docs/deployment.md"
      to: ".env.example"
      via: "references environment configuration"
      pattern: "\\.env"
---

<objective>
Create deployment documentation and verify the full Docker stack end-to-end.

Purpose: Documentation enables the user to deploy without re-reading code. The verification checkpoint confirms the entire stack works: builds, starts, auth prompts, API responds, data persists.
Output: docs/deployment.md, verified working Docker stack
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-docker-deployment-auth/08-RESEARCH.md

@.planning/phases/08-docker-deployment-auth/08-03-SUMMARY.md
@.planning/phases/08-docker-deployment-auth/08-04-SUMMARY.md

@docker-compose.yml
@Caddyfile
@.env.example
@scripts/run-local.sh
@scripts/deploy-gcp.sh
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create deployment documentation</name>
  <files>docs/deployment.md</files>
  <action>
Create directory `docs/` at project root if it does not exist.

Create `docs/deployment.md` with these sections:

**1. Overview**
- DataVisor runs as a 3-service Docker stack: backend (FastAPI + DuckDB + Qdrant), frontend (Next.js), and Caddy (reverse proxy + auth + HTTPS)
- All traffic goes through Caddy on ports 80/443. Backend and frontend are not exposed directly.
- Single-user basic auth is handled by Caddy at the proxy layer -- no application code changes needed.

**2. Prerequisites**
- Docker and Docker Compose v2 (`docker compose` command, not `docker-compose`)
- For GCP deployment: `gcloud` CLI authenticated with a project

**3. Quick Start (Local)**
- Copy .env.example to .env: `cp .env.example .env`
- Generate password hash: `docker run --rm caddy:2-alpine caddy hash-password --plaintext 'your-password'`
- Edit .env and set `AUTH_PASSWORD_HASH` to the output
- Run: `./scripts/run-local.sh` or `docker compose up --build -d`
- Access at http://localhost (username: admin, password: what you set)
- Stop: `docker compose down`

**4. Environment Variables**
- Table of all env vars from .env.example with descriptions:
  - `DOMAIN` (default: localhost) -- set to your domain for auto-HTTPS via Let's Encrypt
  - `AUTH_USERNAME` (default: admin) -- basic auth username
  - `AUTH_PASSWORD_HASH` (required) -- bcrypt hash from `caddy hash-password`
  - `DATAVISOR_DB_PATH` -- DuckDB database path (inside container)
  - `DATAVISOR_BEHIND_PROXY` -- set true when running behind Caddy
  - Other DATAVISOR_* vars with their defaults

**5. GCP Deployment**
- Set environment: `export GCP_PROJECT_ID=your-project`
- Optional overrides: `GCP_ZONE`, `GCP_INSTANCE`, `GCP_MACHINE_TYPE`, `GCP_DISK_SIZE`
- Run: `./scripts/deploy-gcp.sh`
- SSH into VM: `gcloud compute ssh datavisor --zone=us-central1-a`
- Configure .env on the VM (copy .env.example, set AUTH_PASSWORD_HASH and DOMAIN)
- Build and start: `docker compose up -d --build`
- Access at http://EXTERNAL_IP or https://yourdomain.com

**6. Custom Domain with HTTPS**
- Point DNS A record to the VM's external IP
- Set `DOMAIN=yourdomain.com` in .env
- Restart Caddy: `docker compose restart caddy`
- Caddy auto-provisions Let's Encrypt certificate (first request takes ~30 seconds)

**7. Data Persistence**
- All data is stored in `./data/` directory (bind-mounted to `/app/data` in container)
- Contains: DuckDB database, Qdrant vector store, thumbnail cache
- Persists across `docker compose down` and `docker compose up`
- To backup: copy the entire `data/` directory
- IMPORTANT: DuckDB creates WAL and temp files alongside the .duckdb file -- always backup the entire `data/` directory, not individual files

**8. Updating**
- `git pull`
- `docker compose up --build -d` (rebuilds images with new code)
- Data in `./data/` is preserved

**9. Troubleshooting**
- "Connection refused" -- check `docker compose ps` and `docker compose logs caddy`
- "401 Unauthorized" -- verify AUTH_PASSWORD_HASH in .env is a valid bcrypt hash
- "CORS errors in browser" -- ensure DATAVISOR_BEHIND_PROXY=true in backend environment
- "Broken images" -- datasets ingested before Docker store host paths; re-ingest inside Docker
- "Timeout on GCP" -- check firewall rules: `gcloud compute firewall-rules list`
- "SSE streams not working" -- Caddy auto-flushes text/event-stream; check backend logs

**10. Architecture**
- Simple diagram showing: User -> Caddy (80/443) -> /api/* -> Backend (8000), /* -> Frontend (3000)
- Note that Qdrant runs in local embedded mode inside the backend container (not a separate service)

Write in concise, direct style. No marketing language. Each section should be immediately actionable.
  </action>
  <verify>Confirm docs/deployment.md exists and contains all 10 sections. Check that it references the actual script names and env vars from the project.</verify>
  <done>docs/deployment.md provides complete deployment guide covering local setup, GCP deployment, custom domain HTTPS, data persistence, updating, and troubleshooting.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete Docker deployment stack: Dockerfiles for backend and frontend, Caddyfile with basic auth, docker-compose.yml with 3 services, local run script, GCP deployment scripts, and deployment documentation.</what-built>
  <how-to-verify>
1. Generate a test password hash:
   `docker run --rm caddy:2-alpine caddy hash-password --plaintext 'test123'`
2. Create .env from .env.example and set AUTH_PASSWORD_HASH to the output
3. Run: `docker compose up --build` (foreground to see logs)
4. Wait for builds to complete (first build takes 5-15 minutes for PyTorch)
5. Open http://localhost in browser -- should get a basic auth prompt
6. Enter credentials (admin / test123) -- should see DataVisor UI
7. Navigate to a dataset page -- verify grid loads with images
8. Check that API endpoints work: curl -u admin:test123 http://localhost/api/health
9. Run `docker compose down` then `docker compose up -d` -- verify data persists
10. Review docs/deployment.md for accuracy and completeness
  </how-to-verify>
  <resume-signal>Type "approved" if the Docker stack works end-to-end, or describe any issues encountered.</resume-signal>
</task>

</tasks>

<verification>
1. docs/deployment.md exists with all sections (Overview through Troubleshooting)
2. `docker compose up --build` starts all 3 services without errors
3. http://localhost prompts for basic auth credentials
4. After auth, DataVisor UI loads and API endpoints respond
5. Data persists across container restart cycles
</verification>

<success_criteria>
- Deployment docs cover local setup, GCP deployment, custom domain, and troubleshooting
- Full Docker stack verified working end-to-end by user
- Auth prompt appears before any content is accessible
- Data persists across container restarts
</success_criteria>

<output>
After completion, create `.planning/phases/08-docker-deployment-auth/08-05-SUMMARY.md`
</output>
