---
phase: 05-embeddings-visualization
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - app/services/reduction_service.py
  - app/routers/embeddings.py
  - app/main.py
  - app/dependencies.py
  - app/models/embedding.py
autonomous: true

must_haves:
  truths:
    - "User can POST to trigger UMAP dimensionality reduction for a dataset's embeddings"
    - "UMAP reduction runs as a background task with SSE progress streaming"
    - "Reduced 2D coordinates (x, y) are stored back in the DuckDB embeddings table"
    - "User can GET the 2D coordinates for all samples in a dataset as a JSON array"
    - "UMAP produces consistent layouts across runs (fixed random_state=42)"
    - "Re-running reduction replaces previous coordinates (not duplicates)"
  artifacts:
    - path: "app/services/reduction_service.py"
      provides: "UMAP fit_transform wrapper, background reduction task with progress"
      contains: "umap.UMAP"
    - path: "app/routers/embeddings.py"
      provides: "POST reduce, GET reduce/progress, GET coordinates endpoints"
      contains: "reduce"
    - path: "app/models/embedding.py"
      provides: "ReductionProgress, EmbeddingPoint models"
      exports: ["ReductionProgress", "EmbeddingPoint"]
  key_links:
    - from: "app/routers/embeddings.py"
      to: "app/services/reduction_service.py"
      via: "background_tasks.add_task(reduction_service.reduce_embeddings, ...)"
      pattern: "add_task.*reduce_embeddings"
    - from: "app/services/reduction_service.py"
      to: "embeddings table"
      via: "SELECT vector, then UPDATE x, y after UMAP"
      pattern: "UPDATE embeddings SET x"
    - from: "app/routers/embeddings.py GET coordinates"
      to: "embeddings + samples tables"
      via: "JOIN to get x, y, file_name, thumbnail_path per sample"
      pattern: "JOIN samples"
---

<objective>
Add UMAP dimensionality reduction to convert stored 768-dim embeddings into 2D scatter plot coordinates, with background task execution and SSE progress streaming.

Purpose: Raw 768-dim embeddings are not visualizable. UMAP reduction produces the 2D (x, y) coordinates that Plan 03's deck.gl scatter plot will render. This plan also provides the coordinates endpoint that the frontend will fetch.

Output: A reduction service wrapping umap-learn, three new endpoints on the embeddings router, and a coordinates query endpoint returning scatter plot data.
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-embeddings-visualization/05-RESEARCH.md
@.planning/phases/05-embeddings-visualization/05-01-SUMMARY.md

Source files to reference (read before implementing):
@app/services/embedding_service.py -- Background task + progress tracking pattern to replicate
@app/routers/embeddings.py -- Existing embedding endpoints to extend
@app/repositories/duckdb_repo.py -- embeddings table schema (vector FLOAT[768], x DOUBLE, y DOUBLE)
@app/main.py -- Lifespan pattern for service registration
@app/dependencies.py -- DI pattern
@app/models/embedding.py -- Existing Pydantic models to extend
</context>

<tasks>

<task type="auto">
  <name>Task 1: Reduction service and Pydantic models</name>
  <files>
    app/services/reduction_service.py
    app/models/embedding.py
  </files>
  <action>
    **1. Extend `app/models/embedding.py` with new models:**
    - `ReductionProgress(BaseModel)`:
      - `status: str` -- "running", "fitting", "complete", "error"
      - `message: str = ""`
    - `EmbeddingPoint(BaseModel)`:
      - `sample_id: str`
      - `x: float`
      - `y: float`
      - `file_name: str`
      - `thumbnail_path: str | None`
    - Note: "fitting" status is used during the UMAP fit_transform call (which can take 10-60s depending on dataset size) to give the user a more specific progress indicator.

    **2. Create `app/services/reduction_service.py`:**

    Class `ReductionService`:
    - **Constructor:** `__init__(self, db: DuckDBRepo)` -- stores db reference. Initialize `self._tasks: dict[str, ReductionProgress] = {}` for in-memory progress tracking.
    - **`get_progress(self, dataset_id: str) -> ReductionProgress`:** Return `self._tasks.get(dataset_id, ReductionProgress(status="idle"))`.
    - **`is_running(self, dataset_id: str) -> bool`:** Check if task status is "running" or "fitting".
    - **`reduce_embeddings(self, dataset_id: str, n_neighbors: int = 15, min_dist: float = 0.1) -> None`:** The background task function.
      1. Set `self._tasks[dataset_id] = ReductionProgress(status="running", message="Loading embeddings from database")`
      2. Get a cursor: `cursor = self.db.connection.cursor()`
      3. Load all embeddings: `SELECT sample_id, vector FROM embeddings WHERE dataset_id = ? ORDER BY sample_id`
      4. If no embeddings found: set status="error", message="No embeddings found. Run embedding generation first." and return.
      5. Convert to numpy: `import numpy as np; vectors = np.array([row[1] for row in results]); sample_ids = [row[0] for row in results]`
      6. Update status: `self._tasks[dataset_id] = ReductionProgress(status="fitting", message=f"Running UMAP on {len(vectors)} embeddings...")`
      7. Run UMAP:
         ```python
         import umap
         reducer = umap.UMAP(
             n_components=2,
             n_neighbors=n_neighbors,
             min_dist=min_dist,
             metric="cosine",
             random_state=42,  # Reproducible layouts (Pitfall 3 from research)
         )
         coords_2d = reducer.fit_transform(vectors)  # shape: (N, 2)
         ```
      8. Update x, y in DuckDB. Use batch UPDATE:
         ```python
         for i, (sid, coord) in enumerate(zip(sample_ids, coords_2d)):
             cursor.execute(
                 "UPDATE embeddings SET x = ?, y = ? WHERE dataset_id = ? AND sample_id = ?",
                 [float(coord[0]), float(coord[1]), dataset_id, sid]
             )
         ```
         Note: UMAP operates on the full matrix at once (not streaming), so the UPDATE is the only batched step. For large datasets (>50k), consider using a staging approach, but for the expected 100k-image ceiling this is fine.
      9. On success: `self._tasks[dataset_id] = ReductionProgress(status="complete", message=f"Reduced {len(vectors)} embeddings to 2D")`
      10. On exception: `self._tasks[dataset_id] = ReductionProgress(status="error", message=str(e))` -- log full traceback
      11. Close cursor

    - **`get_coordinates(self, dataset_id: str, cursor) -> list[dict]`:** Query method (NOT a background task).
      ```python
      result = cursor.execute("""
          SELECT e.sample_id, e.x, e.y, s.file_name, s.thumbnail_path
          FROM embeddings e
          JOIN samples s ON e.sample_id = s.id AND e.dataset_id = s.dataset_id
          WHERE e.dataset_id = ? AND e.x IS NOT NULL
          ORDER BY e.sample_id
      """, [dataset_id]).fetchall()
      return [
          {"sampleId": r[0], "x": r[1], "y": r[2], "fileName": r[3], "thumbnailPath": r[4]}
          for r in result
      ]
      ```
  </action>
  <verify>
    - `python -c "from app.services.reduction_service import ReductionService; print('Service OK')"` succeeds
    - `python -c "from app.models.embedding import ReductionProgress, EmbeddingPoint; print('Models OK')"` succeeds
    - `python -c "import umap; r = umap.UMAP(n_components=2, random_state=42); print('UMAP OK')"` succeeds
  </verify>
  <done>
    ReductionService wraps umap-learn with fixed random_state=42 for reproducible layouts. It loads embeddings from DuckDB, runs UMAP fit_transform, and writes 2D coordinates back to the embeddings table x/y columns. Progress tracking distinguishes "running" (loading data), "fitting" (UMAP computation), and "complete" states.
  </done>
</task>

<task type="auto">
  <name>Task 2: Reduction endpoints and coordinates API</name>
  <files>
    app/routers/embeddings.py
    app/main.py
    app/dependencies.py
  </files>
  <action>
    **1. Add reduction endpoints to `app/routers/embeddings.py`:**

    - **POST `/datasets/{dataset_id}/embeddings/reduce`:**
      - Check if reduction already running (409 Conflict if so)
      - Check if embeddings exist for this dataset (400 if not: "No embeddings found. Generate embeddings first.")
      - `background_tasks.add_task(reduction_service.reduce_embeddings, dataset_id)`
      - Return 202 with `{"status": "started", "message": "UMAP reduction started"}`

    - **GET `/datasets/{dataset_id}/embeddings/reduce/progress`:**
      - Return `EventSourceResponse` with async generator (same SSE pattern as embedding progress)
      - Yield `{"event": "progress", "data": json.dumps(progress.model_dump())}` every 0.5s
      - Break when status is "complete" or "error"

    - **GET `/datasets/{dataset_id}/embeddings/coordinates`:**
      - Call `reduction_service.get_coordinates(dataset_id, cursor)` -- this is a synchronous read, not a background task
      - Return the list of `EmbeddingPoint` objects as JSON array
      - This is the endpoint the frontend scatter plot will fetch
      - If no coordinates exist (empty list), return empty array `[]` (not 404)

    **2. Update `app/main.py`:**
    - In the lifespan, after EmbeddingService creation:
      - Create `ReductionService(db=app.state.db)`
      - Store as `app.state.reduction_service`

    **3. Update `app/dependencies.py`:**
    - Add `get_reduction_service` dependency function
    - Returns `request.app.state.reduction_service`

    **4. Wire dependencies in router:**
    - The reduction endpoints need both `reduction_service` (for reduce/progress) and a cursor (for coordinates query)
    - Follow existing DI patterns from other routers
  </action>
  <verify>
    - `python -c "from app.routers.embeddings import router; print(f'{len(router.routes)} routes')"` shows 6 routes (3 from Plan 01 + 3 new)
    - `python -m pytest tests/ -v --timeout=60` -- all existing tests pass
    - Verify endpoint registration: `python -c "from app.main import app; paths = [r.path for r in app.routes if 'embedding' in str(r.path)]; print(paths)"` shows all 6 embedding endpoint paths including /reduce, /reduce/progress, /coordinates
  </verify>
  <done>
    Three new endpoints extend the embeddings router: POST /reduce triggers UMAP background task, GET /reduce/progress streams SSE events, and GET /coordinates returns the 2D scatter data as JSON array for the frontend. ReductionService registered in lifespan and available via DI.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from app.services.reduction_service import ReductionService; print('OK')"` -- service importable
2. `python -c "from app.models.embedding import ReductionProgress, EmbeddingPoint; print('OK')"` -- models importable
3. `python -m pytest tests/ -v` -- all existing tests pass
4. Verify all 6 embedding endpoints registered: `python -c "from app.main import app; [print(r.path) for r in app.routes if 'embedding' in str(r.path)]"`
5. UMAP library works: `python -c "import numpy as np; import umap; data = np.random.rand(50, 768); result = umap.UMAP(n_components=2, random_state=42).fit_transform(data); print(result.shape)"` outputs `(50, 2)`
</verification>

<success_criteria>
- POST /reduce triggers UMAP as a background task (202 response, non-blocking)
- SSE progress stream distinguishes loading, fitting, and complete states
- UMAP uses random_state=42 for reproducible layouts
- 2D coordinates stored in embeddings table x/y columns
- GET /coordinates returns JSON array of {sampleId, x, y, fileName, thumbnailPath} for scatter plot
- All existing tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/05-embeddings-visualization/05-02-SUMMARY.md`
</output>
