---
phase: 05-embeddings-visualization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/repositories/duckdb_repo.py
  - app/models/embedding.py
  - app/services/embedding_service.py
  - app/routers/embeddings.py
  - app/main.py
  - pyproject.toml
autonomous: true

must_haves:
  truths:
    - "User can POST to trigger embedding generation for a dataset and receive a 202 Accepted response"
    - "Embedding generation runs as a background task (does not block the API request)"
    - "User can GET an SSE progress stream showing processed/total counts and status"
    - "Embeddings are stored in DuckDB as FLOAT[768] vectors with sample_id foreign key"
    - "Re-triggering embedding generation replaces previous embeddings (not duplicates)"
    - "Model loads once at startup (not per-request) to avoid repeated 350MB downloads"
  artifacts:
    - path: "app/services/embedding_service.py"
      provides: "DINOv2 model loading, batch image embedding extraction, background task runner"
      contains: "AutoModel.from_pretrained"
    - path: "app/models/embedding.py"
      provides: "Pydantic models for embedding requests, responses, and progress events"
      exports: ["EmbeddingGenerateRequest", "EmbeddingGenerateResponse", "EmbeddingProgress"]
    - path: "app/routers/embeddings.py"
      provides: "POST generate, GET progress SSE, GET status endpoints"
      contains: "EventSourceResponse"
    - path: "app/repositories/duckdb_repo.py"
      provides: "embeddings table with FLOAT[768] vector column"
      contains: "CREATE TABLE IF NOT EXISTS embeddings"
  key_links:
    - from: "app/routers/embeddings.py"
      to: "app/services/embedding_service.py"
      via: "background_tasks.add_task(embedding_service.generate_embeddings, ...)"
      pattern: "add_task.*generate_embeddings"
    - from: "app/services/embedding_service.py"
      to: "embeddings table"
      via: "DuckDB INSERT INTO embeddings per batch"
      pattern: "INSERT INTO embeddings"
    - from: "app/services/embedding_service.py"
      to: "transformers AutoModel"
      via: "DINOv2 CLS token extraction with torch.no_grad()"
      pattern: "last_hidden_state.*0"
    - from: "app/routers/embeddings.py"
      to: "sse-starlette EventSourceResponse"
      via: "Async generator yielding progress events"
      pattern: "EventSourceResponse"
---

<objective>
Build the embedding generation pipeline so users can trigger DINOv2-based image embedding extraction for a dataset, monitor progress via SSE, and have embeddings stored in DuckDB.

Purpose: Embeddings are the foundation of Phase 5 -- without stored vectors, UMAP reduction (Plan 02) and the scatter plot (Plan 03) have no data to work with. This plan establishes the ML inference pipeline, DuckDB storage schema, and progress streaming.

Output: An embedding service with DINOv2 model management, a background task runner with SSE progress, REST endpoints for triggering and monitoring, and the DuckDB embeddings table.
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-embeddings-visualization/05-RESEARCH.md

Source files to reference (read before implementing):
@app/repositories/duckdb_repo.py -- Schema pattern, where to add embeddings table
@app/services/ingestion.py -- Background task + SSE progress pattern to replicate
@app/routers/datasets.py -- Router registration pattern, endpoint structure
@app/main.py -- Lifespan manager, app.state pattern, router includes
@app/dependencies.py -- DI pattern for services
@app/config.py -- Settings pattern for any new config
@app/services/image_service.py -- Image loading pattern (PIL Image from disk)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install dependencies, create DuckDB schema, and Pydantic models</name>
  <files>
    pyproject.toml
    app/repositories/duckdb_repo.py
    app/models/embedding.py
  </files>
  <action>
    **1. Install Python dependencies:**
    ```bash
    cd /Users/ortizeg/1Projects/⛹️‍♂️\ Next\ Play/code/data-visor
    uv add transformers torch umap-learn sse-starlette
    ```
    Note: `torch` is large (~2GB). Use CPU-only install: `uv add torch --extra-index-url https://download.pytorch.org/whl/cpu` if available, otherwise standard `uv add torch` is fine (it auto-detects platform). `umap-learn` and `sse-starlette` are small.

    **2. Add embeddings table to `app/repositories/duckdb_repo.py`:**
    In `initialize_schema()`, add after the saved_views table:
    ```python
    # Phase 5: Embeddings table for image embeddings and 2D reduced coordinates
    self.connection.execute("""
        CREATE TABLE IF NOT EXISTS embeddings (
            sample_id       VARCHAR NOT NULL,
            dataset_id      VARCHAR NOT NULL,
            model_name      VARCHAR NOT NULL,
            vector          FLOAT[768],
            x               DOUBLE,
            y               DOUBLE
        )
    """)
    ```
    The `vector` column stores the full 768-dim DINOv2-base embedding. `x` and `y` are NULL initially and populated by UMAP reduction (Plan 02). `model_name` tracks which model generated the embedding (e.g., "dinov2-base").

    **3. Create `app/models/embedding.py`:**
    - `EmbeddingGenerateRequest(BaseModel)`:
      - `model_name: str = "dinov2-base"` -- which model to use (default DINOv2-base)
    - `EmbeddingGenerateResponse(BaseModel)`:
      - `dataset_id: str`
      - `status: str` -- "started" or "already_running"
      - `message: str`
    - `EmbeddingProgress(BaseModel)`:
      - `status: str` -- "running", "complete", "error"
      - `processed: int`
      - `total: int`
      - `message: str = ""`
    - `EmbeddingStatus(BaseModel)`:
      - `dataset_id: str`
      - `has_embeddings: bool`
      - `embedding_count: int`
      - `model_name: str | None`
      - `has_reduction: bool` -- whether x,y are populated (for Plan 02)
  </action>
  <verify>
    - `cd /Users/ortizeg/1Projects/⛹️‍♂️\ Next\ Play/code/data-visor && python -c "import transformers; import torch; import umap; from sse_starlette.sse import EventSourceResponse; print('All deps OK')"` succeeds
    - `python -c "from app.models.embedding import EmbeddingGenerateRequest, EmbeddingProgress, EmbeddingStatus; print('Models OK')"` succeeds
    - `python -c "from app.repositories.duckdb_repo import DuckDBRepo; db = DuckDBRepo('/tmp/test_embed.db'); db.initialize_schema(); print(db.connection.execute('DESCRIBE embeddings').fetchall())"` shows the embeddings table with vector FLOAT[768] column
  </verify>
  <done>
    All ML dependencies installed. DuckDB embeddings table created with FLOAT[768] vector column, x/y coordinate columns for UMAP output, and model_name tracking. Pydantic models define the API contract for generation, progress, and status.
  </done>
</task>

<task type="auto">
  <name>Task 2: Embedding service with DINOv2 model and background task generation</name>
  <files>
    app/services/embedding_service.py
    app/routers/embeddings.py
    app/main.py
    app/dependencies.py
  </files>
  <action>
    **1. Create `app/services/embedding_service.py`:**

    Class `EmbeddingService`:
    - **Constructor:** `__init__(self, db: DuckDBRepo, image_service: ImageService)` -- stores db and image_service references. Initialize `self._model = None`, `self._processor = None`, `self._tasks: dict[str, EmbeddingProgress] = {}` (in-memory task state per dataset).
    - **`load_model(self, model_name: str = "dinov2-base") -> None`:** Load model at app startup (called from lifespan).
      - Map model_name to HuggingFace model ID: `{"dinov2-base": "facebook/dinov2-base", "dinov2-small": "facebook/dinov2-small"}`
      - `self._processor = AutoImageProcessor.from_pretrained(hf_model_id)`
      - `self._model = AutoModel.from_pretrained(hf_model_id)`
      - `self._model.eval()` -- set to eval mode (no dropout)
      - Detect device: `torch.device("mps") if torch.backends.mps.is_available() else torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")`
      - `self._model.to(device)` -- move model to best available device
      - Store `self._device` and `self._model_name`
      - Log model loaded message with device info
    - **`get_progress(self, dataset_id: str) -> EmbeddingProgress`:** Return `self._tasks.get(dataset_id, EmbeddingProgress(status="idle", processed=0, total=0))`.
    - **`is_running(self, dataset_id: str) -> bool`:** Return `self._tasks.get(dataset_id, {}).status == "running"` (check if task already running to prevent duplicate generation).
    - **`generate_embeddings(self, dataset_id: str) -> None`:** The background task function.
      1. Set `self._tasks[dataset_id] = EmbeddingProgress(status="running", processed=0, total=0)`
      2. Use a cursor from `self.db.connection.cursor()` for all DB operations in this task
      3. Query sample count: `SELECT COUNT(*) FROM samples WHERE dataset_id = ?`
      4. Update total: `self._tasks[dataset_id].total = count`
      5. Delete existing embeddings: `DELETE FROM embeddings WHERE dataset_id = ?`
      6. Query samples in batches: `SELECT id, file_name FROM samples WHERE dataset_id = ? ORDER BY id LIMIT ? OFFSET ?` with batch_size=32
      7. For each batch:
         a. Load images: use `self.image_service` to get original image paths, open with PIL `Image.open(path).convert("RGB")`
         b. Skip samples where image file is missing (log warning, continue)
         c. Preprocess: `inputs = self._processor(images=pil_images, return_tensors="pt").to(self._device)`
         d. Extract CLS token: `with torch.no_grad(): outputs = self._model(**inputs); cls = outputs.last_hidden_state[:, 0, :].cpu().numpy()`
         e. Build insert rows: `[(sample_id, dataset_id, self._model_name, vec.tolist(), None, None) for sample_id, vec in zip(batch_ids, cls)]`
         f. `cursor.executemany("INSERT INTO embeddings VALUES (?, ?, ?, ?, ?, ?)", rows)`
         g. Update progress: `self._tasks[dataset_id].processed += len(batch_ids)`
      8. On success: `self._tasks[dataset_id].status = "complete"; self._tasks[dataset_id].message = f"Generated {total} embeddings"`
      9. On exception: `self._tasks[dataset_id].status = "error"; self._tasks[dataset_id].message = str(e)` -- log full traceback
      10. Close the cursor when done

    **Important anti-patterns to avoid:**
    - Do NOT load model per-request (Pitfall 1 from research). Load once in lifespan.
    - Do NOT embed all images at once (Pitfall 2). Process in batches of 32.
    - Use `torch.no_grad()` context to disable gradient tracking (saves memory).
    - Keep write transactions small (commit per batch) to avoid blocking grid reads (Pitfall 7).

    **2. Create `app/routers/embeddings.py`:**
    - Router with prefix `/datasets/{dataset_id}/embeddings`, tags=["embeddings"]
    - **POST `/datasets/{dataset_id}/embeddings/generate`:**
      - Accept optional `EmbeddingGenerateRequest` body (defaults to dinov2-base)
      - Check if generation already running for this dataset (409 Conflict if so)
      - Verify dataset exists (404 if not)
      - `background_tasks.add_task(embedding_service.generate_embeddings, dataset_id)`
      - Return 202 with `EmbeddingGenerateResponse(dataset_id=dataset_id, status="started", message="Embedding generation started")`
    - **GET `/datasets/{dataset_id}/embeddings/progress`:**
      - Return `EventSourceResponse` from sse-starlette
      - Async generator: loop every 0.5s, yield `{"event": "progress", "data": json.dumps(progress.model_dump())}`. Break when status is "complete" or "error".
      - This follows the SSE pattern from research (Pattern 2), NOT the sync generator pattern from Phase 1 ingestion (sse-starlette is the proper SSE library).
    - **GET `/datasets/{dataset_id}/embeddings/status`:**
      - Query DuckDB: `SELECT COUNT(*), MAX(model_name), COUNT(x) FILTER (WHERE x IS NOT NULL) FROM embeddings WHERE dataset_id = ?`
      - Return `EmbeddingStatus` with has_embeddings, embedding_count, model_name, has_reduction

    **3. Update `app/main.py`:**
    - In the lifespan context manager, after existing service initialization:
      - Create `EmbeddingService(db=app.state.db, image_service=app.state.image_service)`
      - Call `embedding_service.load_model()` -- this pre-downloads the DINOv2 model
      - Store as `app.state.embedding_service = embedding_service`
    - Add router include: `app.include_router(embeddings_router)`
    - Import: `from app.routers.embeddings import router as embeddings_router`

    **4. Update `app/dependencies.py`:**
    - Add `get_embedding_service` dependency function following same pattern as other service DI functions
    - Returns `request.app.state.embedding_service`
  </action>
  <verify>
    - `cd /Users/ortizeg/1Projects/⛹️‍♂️\ Next\ Play/code/data-visor && python -c "from app.services.embedding_service import EmbeddingService; print('Service OK')"` succeeds
    - `python -c "from app.routers.embeddings import router; print(f'{len(router.routes)} routes')"` shows 3 routes
    - `python -m pytest tests/ -v --timeout=60` -- all existing tests still pass (no regressions)
    - Manual sanity: `python -c "from app.main import app; print([r.path for r in app.routes if 'embedding' in str(r.path)])"` shows the 3 embedding endpoints
  </verify>
  <done>
    EmbeddingService loads DINOv2 model once at startup, extracts CLS token embeddings in batches of 32 with torch.no_grad(), stores FLOAT[768] vectors in DuckDB, and tracks progress in memory. Router provides POST /generate (triggers background task), GET /progress (SSE stream), and GET /status (embedding availability check). Model auto-detects MPS/CUDA/CPU device.
  </done>
</task>

</tasks>

<verification>
1. `python -c "import transformers, torch, umap; from sse_starlette.sse import EventSourceResponse; print('Deps OK')"` -- all dependencies importable
2. `python -c "from app.repositories.duckdb_repo import DuckDBRepo; db = DuckDBRepo('/tmp/test.db'); db.initialize_schema(); print(db.connection.execute('DESCRIBE embeddings').fetchall())"` -- embeddings table exists with FLOAT[768]
3. `python -c "from app.services.embedding_service import EmbeddingService; print('Service importable')"` -- service class importable
4. `python -m pytest tests/ -v` -- all existing tests pass (no regressions)
5. Verify router registration: `python -c "from app.main import app; print([r.path for r in app.routes if 'embedding' in str(r.path)])"` shows 3 endpoint paths
</verification>

<success_criteria>
- DINOv2 model loads once at app startup and stays in memory
- POST endpoint triggers background embedding generation (non-blocking 202 response)
- SSE endpoint streams progress events (processed count, total, status)
- Embeddings stored as FLOAT[768] in DuckDB with sample_id and model_name
- Re-generation replaces previous embeddings (DELETE before INSERT)
- Status endpoint reports embedding availability for frontend feature detection
- All existing tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/05-embeddings-visualization/05-01-SUMMARY.md`
</output>
