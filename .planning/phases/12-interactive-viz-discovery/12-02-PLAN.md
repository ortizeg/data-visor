---
phase: 12-interactive-viz-discovery
plan: 02
type: execute
wave: 2
depends_on: ["12-01"]
files_modified:
  - app/services/evaluation.py
  - app/routers/statistics.py
  - app/models/evaluation.py
  - frontend/src/hooks/use-confusion-cell.ts
  - frontend/src/components/stats/confusion-matrix.tsx
  - frontend/src/components/stats/evaluation-panel.tsx
autonomous: true

must_haves:
  truths:
    - "User can click any non-zero cell in the confusion matrix and the grid shows only samples matching that GT/predicted class pair"
    - "Zero-value cells in the confusion matrix are not clickable"
    - "After clicking a confusion matrix cell, the grid tab activates automatically"
  artifacts:
    - path: "app/routers/statistics.py"
      provides: "GET /datasets/{id}/confusion-cell-samples endpoint"
      contains: "confusion-cell-samples"
    - path: "app/services/evaluation.py"
      provides: "get_confusion_cell_samples helper that re-runs IoU matching for a specific cell"
      contains: "def get_confusion_cell_samples"
    - path: "frontend/src/hooks/use-confusion-cell.ts"
      provides: "Hook to fetch sample IDs for a confusion matrix cell"
      exports: ["useConfusionCellSamples"]
    - path: "frontend/src/components/stats/confusion-matrix.tsx"
      provides: "onClick handler on matrix cells"
      contains: "onClick"
  key_links:
    - from: "frontend/src/components/stats/confusion-matrix.tsx"
      to: "frontend/src/hooks/use-confusion-cell.ts"
      via: "onCellClick callback triggers fetch"
      pattern: "onCellClick|useConfusionCellSamples"
    - from: "frontend/src/hooks/use-confusion-cell.ts"
      to: "app/routers/statistics.py"
      via: "GET /datasets/{id}/confusion-cell-samples API call"
      pattern: "confusion-cell-samples"
    - from: "frontend/src/hooks/use-confusion-cell.ts"
      to: "frontend/src/stores/filter-store.ts"
      via: "setSampleIdFilter with returned sample IDs"
      pattern: "setSampleIdFilter"
---

<objective>
Add clickable confusion matrix cells that filter the grid to samples matching a specific GT/predicted class pair.

Purpose: Implements TRIAGE-04 -- users can explore model confusion patterns by clicking any cell in the confusion matrix, which immediately filters the sample grid to show the actual images that contributed to that cell's count.

Output: Backend endpoint that maps confusion matrix cells to sample IDs via IoU matching, and frontend wiring that sends cell clicks through the sampleIdFilter pipeline into the grid.
</objective>

<execution_context>
@/Users/ortizeg/.claude/get-shit-done/workflows/execute-plan.md
@/Users/ortizeg/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/12-interactive-viz-discovery/12-RESEARCH.md
@.planning/phases/12-interactive-viz-discovery/12-01-SUMMARY.md

@app/services/evaluation.py
@app/routers/statistics.py
@app/models/evaluation.py
@app/dependencies.py
@frontend/src/stores/filter-store.ts
@frontend/src/stores/ui-store.ts
@frontend/src/components/stats/confusion-matrix.tsx
@frontend/src/components/stats/evaluation-panel.tsx
@frontend/src/hooks/use-evaluation.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Backend confusion-cell-samples endpoint</name>
  <files>
    app/services/evaluation.py
    app/routers/statistics.py
    app/models/evaluation.py
  </files>
  <action>
    1. In `app/models/evaluation.py`, add a response model:
       ```python
       class ConfusionCellSamplesResponse(BaseModel):
           actual_class: str
           predicted_class: str
           sample_ids: list[str]
           count: int
       ```

    2. In `app/services/evaluation.py`, add a new function `get_confusion_cell_samples`:
       ```python
       def get_confusion_cell_samples(
           cursor: DuckDBPyConnection,
           dataset_id: str,
           source: str,
           actual_class: str,
           predicted_class: str,
           iou_threshold: float,
           conf_threshold: float,
           split: str | None = None,
       ) -> list[str]:
       ```

       This function must re-run the IoU matching logic (similar to how `_compute_confusion_matrix` works internally via supervision) but return sample IDs instead of counts.

       Algorithm:
       a. Call existing `_load_detections(cursor, dataset_id, source, split=split)` to get gt_by_sample, pred_by_sample, class_names.
       b. Build `class_name_to_id` mapping.
       c. For each sample_id in the union of gt and pred samples:
          - Build supervision Detections objects for GT and predictions (reuse `_build_detections`).
          - Filter predictions by conf_threshold.
          - Run IoU matching (using `_compute_iou_matrix`) with greedy assignment:
            - For each pred sorted by confidence descending:
              - Find same-class GT boxes.
              - If best IoU >= iou_threshold and GT box not yet matched:
                - It's a match. Record which pred_class matched which gt_class.
          - Collect unmatched GTs (these map to actual=X, predicted=background).
          - Collect unmatched preds (these map to actual=background, predicted=X).
          - Check if this sample has any detection where:
            - actual=actual_class AND predicted=predicted_class
            - OR (for "background" as actual_class): unmatched prediction with class=predicted_class
            - OR (for "background" as predicted_class): unmatched GT with class=actual_class
          - If yes, add sample_id to results.
       d. Return the list of matching sample_ids.

       **Important:** The "background" class in the confusion matrix represents unmatched detections/GT boxes. Handle this:
       - `actual_class="background"` means: false positive predictions of `predicted_class` (no matching GT).
       - `predicted_class="background"` means: false negatives of `actual_class` (GT with no matching prediction).
       - Both non-background: matched predictions where GT class is `actual_class` and pred class is `predicted_class`.

    3. In `app/routers/statistics.py`, add the endpoint:
       ```python
       @router.get("/{dataset_id}/confusion-cell-samples", response_model=ConfusionCellSamplesResponse)
       def get_confusion_cell_samples_endpoint(
           dataset_id: str,
           actual_class: str = Query(...),
           predicted_class: str = Query(...),
           source: str = Query("prediction"),
           iou_threshold: float = Query(0.5, ge=0.1, le=1.0),
           conf_threshold: float = Query(0.25, ge=0.0, le=1.0),
           split: str | None = Query(None),
           db: DuckDBRepo = Depends(get_db),
       ) -> ConfusionCellSamplesResponse:
       ```
       - Verify dataset exists (existing pattern).
       - Call `get_confusion_cell_samples(...)` from evaluation service.
       - Return the response model with sample_ids, count, actual_class, predicted_class.
  </action>
  <verify>
    Backend starts without errors: `cd /path/to/project && python -c "from app.services.evaluation import get_confusion_cell_samples; print('OK')"`
    Endpoint is registered: check `GET /datasets/{id}/confusion-cell-samples` appears in FastAPI docs.
  </verify>
  <done>
    GET /datasets/{id}/confusion-cell-samples endpoint exists and returns sample IDs for a given (actual_class, predicted_class) pair by re-running IoU matching. Handles "background" class for false positives and false negatives.
  </done>
</task>

<task type="auto">
  <name>Task 2: Frontend confusion matrix cell click -> grid filter</name>
  <files>
    frontend/src/hooks/use-confusion-cell.ts
    frontend/src/components/stats/confusion-matrix.tsx
    frontend/src/components/stats/evaluation-panel.tsx
  </files>
  <action>
    1. Create `frontend/src/hooks/use-confusion-cell.ts`:
       - Export a function (not a hook -- this is an imperative action, not reactive data) called `fetchConfusionCellSamples`:
         ```typescript
         export async function fetchConfusionCellSamples(
           datasetId: string,
           actualClass: string,
           predictedClass: string,
           source: string,
           iouThreshold: number,
           confThreshold: number,
           split: string | null,
         ): Promise<string[]>
         ```
       - Uses `apiFetch` to call `GET /datasets/{datasetId}/confusion-cell-samples` with query params.
       - Returns the `sample_ids` array from the response.
       - Also export the response type: `ConfusionCellSamplesResponse { actual_class: string; predicted_class: string; sample_ids: string[]; count: number; }`

    2. Update `confusion-matrix.tsx`:
       - Add an `onCellClick` prop to `ConfusionMatrixProps`:
         ```typescript
         onCellClick?: (actualClass: string, predictedClass: string) => void;
         ```
       - On each `<td>` data cell, add:
         - `onClick={() => { if (matrix[ri][ci] > 0 && onCellClick) onCellClick(labels[ri], labels[ci]); }}`
         - `className` should include `cursor-pointer hover:ring-2 hover:ring-blue-500 hover:ring-inset` when the raw matrix value > 0 (check the original un-normalized `matrix` prop -- note: currently only normalized is available. Either pass the raw matrix as a second prop, or check `norm > 0` which is equivalent since norm > 0 iff raw > 0).
         - For zero cells, no cursor change and no onClick.
       - The component needs access to the RAW (un-normalized) matrix to know if a cell has data. Currently the component receives `matrix` (raw counts) and normalizes internally. So `matrix[ri][ci] > 0` works directly.

    3. Update `evaluation-panel.tsx`:
       - Import `fetchConfusionCellSamples` from the new hook file.
       - Import `useFilterStore` from filter-store and `useUIStore` from ui-store.
       - Add a `handleCellClick` callback:
         ```typescript
         const handleCellClick = useCallback(async (actualClass: string, predictedClass: string) => {
           try {
             const sampleIds = await fetchConfusionCellSamples(
               datasetId, actualClass, predictedClass,
               source, debouncedIou, debouncedConf, split,
             );
             useFilterStore.getState().setSampleIdFilter(sampleIds);
             useUIStore.getState().setActiveTab("grid");
           } catch (err) {
             console.error("Failed to fetch confusion cell samples:", err);
           }
         }, [datasetId, source, debouncedIou, debouncedConf, split]);
         ```
       - Pass `onCellClick={handleCellClick}` to the `<ConfusionMatrix>` component.
  </action>
  <verify>
    TypeScript compiles: `cd frontend && npx tsc --noEmit` passes.
    confusion-matrix.tsx has onClick on td elements with cursor-pointer class.
    evaluation-panel.tsx passes onCellClick to ConfusionMatrix.
    use-confusion-cell.ts exports fetchConfusionCellSamples.
  </verify>
  <done>
    Clicking a non-zero confusion matrix cell fetches matching sample IDs from the backend, sets the sampleIdFilter, and switches to the grid tab showing only those samples. Zero cells are not clickable.
  </done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `cd frontend && npx tsc --noEmit`
2. Backend starts: `cd backend && python -c "from app.routers.statistics import router; print('OK')"`
3. GET /datasets/{id}/confusion-cell-samples endpoint registered in FastAPI
4. confusion-matrix.tsx cells have onClick handlers
5. evaluation-panel.tsx passes onCellClick to ConfusionMatrix
6. Clicking a cell calls setSampleIdFilter and switches to grid tab
</verification>

<success_criteria>
- TRIAGE-04: User can click any non-zero confusion matrix cell to filter the grid to matching samples
- Zero-value cells are visually inert (no cursor pointer, no click handler)
- The grid tab activates automatically after cell click
- Backend correctly maps confusion matrix cells to sample IDs including "background" class handling
</success_criteria>

<output>
After completion, create `.planning/phases/12-interactive-viz-discovery/12-02-SUMMARY.md`
</output>
